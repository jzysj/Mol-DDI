import os
import numpy as np
import networkx as nx
import torch
import os.path as osp
import yaml
import re
from torch_geometric.data import InMemoryDataset, Dataset
from torch_geometric.loader import DataLoader
from rdkit import Chem
from rdkit.Chem import AllChem, rdmolops
from tqdm import tqdm
from torch_geometric import data as DATA
# 读取训练数据
# 输入数据路径,生成药物列表、字典、正样本对

smiles_path = "./Dataset/drug_smiles.txt"


def sqrt(drug_adj):
    mat = np.zeros((len(drug_adj), len(drug_adj)), dtype=float)
    adj = np.array(drug_adj).astype(float)
    for i in range(len(drug_adj)):
        for j in range(len(drug_adj)):
            mat[i][j] = np.sqrt(np.sum(np.square(adj[i] - adj[j])))
    return mat


# 这里将，所有的药物分子的原子信息存在字典中
# key:name,[atoms]:,[smiles]:


def read_smiles(smiles_path):
    drug_sm_dic = {}
    with open(smiles_path, 'r') as fi:
        for i in fi.readlines():
            drug_sm_dic[i.strip().split('\t')[0]] = i.strip().split('\t')[1]
    return drug_sm_dic


print("read_data_smiles")
data_smiles = read_smiles(smiles_path)
drugs = []
config = yaml.load(open("config_finetune.yaml", "r"), Loader=yaml.FullLoader)
if config["task_name"] == "BIOSNAP":
    data_path = "./Dataset/ChCh-Miner_durgbank-chem-chem.tsv"
    with open('./Dataset/biosnap_drugs.txt', 'r') as fi:
        for i in fi.readlines():
            drugs.append(i.strip())
    fi.close()
elif config["task_name"] == "AdverseDDI":
    data_path = "./Dataset/AdverseDDI.edgelist"
    with open('./Dataset/addverDDIs_drugs.txt', 'r') as fi:
        for i in fi.readlines():
            drugs.append(i.strip())
    fi.close()
elif config["task_name"] == "drugbank":
    data_path = "./Dataset/drugbank.txt"
    with open('./Dataset/drugbak_drugs.txt', 'r') as fi:
        for i in fi.readlines():
            drugs.append(i.strip())
    fi.close()


# 读取所有的药物smiles串
def Calculate_atoms_adj(smiles):
    mol = Chem.MolFromSmiles(smiles)
    mol = Chem.AddHs(mol)
    # print(mol.GetNumAtoms())
    # 获得3D位置矩阵
    AllChem.EmbedMolecule(mol)
    statis = Chem.MolToMolBlock(mol)
    info = re.findall(r'(-?\d.\d+)\s+(-?\d.\d+)\s+(-?\d.\d+)\s(\w+)\s+', statis)
    # 坐标和原子信息
    xyz = np.asarray(info)[:, 0:-1].astype(float)
    # 提取坐标信息
    adjacent = sqrt(xyz)
    # 计算相对位置
    atoms = np.asarray(info)[:, -1]
    # 生成原子列表
    # 生成0-2之间的位置索引
    adj1 = torch.LongTensor(np.asarray(np.where((adjacent > 0) & (adjacent < 2))))
    new_adj1 = np.where((adjacent <= 0) | (adjacent >= 2), 0, adjacent)
    features1 = Calculate_feature(new_adj1, atoms)

    adj2 = torch.LongTensor(np.asarray(np.where((adjacent >= 2) & (adjacent < 4))))
    new_adj2 = np.where((adjacent < 2) | (adjacent >= 4), 0, adjacent)
    features2 = Calculate_feature(new_adj2, atoms)

    adj3 = torch.LongTensor(np.asarray(np.where((adjacent >= 4) & (adjacent < 6))))
    new_adj3 = np.where((adjacent < 4) | (adjacent >= 6), 0, adjacent)
    features3 = Calculate_feature(new_adj3, atoms)

    adj4 = torch.LongTensor(np.asarray(np.where((adjacent >= 6) & (adjacent < 8))))
    new_adj4 = np.where((adjacent < 6) | (adjacent >= 8), 0, adjacent)
    features4 = Calculate_feature(new_adj4, atoms)

    adj5 = torch.LongTensor(np.asarray(np.where((adjacent >= 8))))
    new_adj5 = np.where(adjacent < 8, 0, adjacent)
    features5 = Calculate_feature(new_adj5, atoms)

    return adj5, adj4, adj3, adj2, adj1, features1, features2, features3, features4, features5



def read_data(drugs_list):
    drug_info = {}
    # 初始化无向图
    for drug in drugs_list:
        smiles = data_smiles[drug]
        adj5, adj4, adj3, adj2, adj1, features1, features2, features3, features4, features5 = Calculate_atoms_adj(smiles)
        drug_info[drug] = {}
        drug_info[drug]['adjacent1'] = adj1
        drug_info[drug]['adjacent2'] = adj2
        drug_info[drug]['adjacent3'] = adj3
        drug_info[drug]['adjacent4'] = adj4
        drug_info[drug]['adjacent5'] = adj5
        drug_info[drug]['features1'] = features1
        drug_info[drug]['features2'] = features2
        drug_info[drug]['features3'] = features3
        drug_info[drug]['features4'] = features4
        drug_info[drug]['features5'] = features5
        drug_info[drug]['index'] = drugs_list.index(drug)

    return drug_info


def Calculate_feature(dis_mat, all_atoms):
    Feat_mat = np.zeros((len(all_atoms), 62), dtype=float)
    for a in range(len(dis_mat[0, :])):
        for b in range(len(dis_mat[:, 0])):
            if dis_mat[a][b] == 0:
                continue
            if all_atoms[b] == 'C':
                if dis_mat[a][b] >= 10:
                    Feat_mat[a, 18] += 1
                else:
                    Feat_mat[a, int((dis_mat[a, b] - 1) * 2)] += 1
            elif all_atoms[b] == 'H':
                if dis_mat[a][b] >= 10:
                    Feat_mat[a, 37] += 1
                else:
                    Feat_mat[a, 19 + int((dis_mat[a, b] - 1) * 2)] += 1
            elif all_atoms[b] == 'O':
                if dis_mat[a][b] < 2.5:
                    Feat_mat[a, 38] += 1
                elif dis_mat[a][b] < 5:
                    Feat_mat[a, 39] += 1
                elif dis_mat[a][b] < 7.5:
                    Feat_mat[a, 40] += 1
                else:
                    Feat_mat[a, 41] += 1
            elif all_atoms[b] == 'N':
                if dis_mat[a][b] <= 2.5:
                    Feat_mat[a, 42] += 1
                elif dis_mat[a][b] < 5:
                    Feat_mat[a, 43] += 1
                elif dis_mat[a][b] < 7.5:
                    Feat_mat[a, 44] += 1
                else:
                    Feat_mat[a, 45] += 1
            elif all_atoms[b] == 'P':
                if dis_mat[a][b] < 5:
                    Feat_mat[a, 46] += 1
                else:
                    Feat_mat[a, 47] += 1
            elif all_atoms[b] == 'Cl' or all_atoms[a] == 'CL':
                if dis_mat[a][b] < 5:
                    Feat_mat[a, 48] += 1
                else:
                    Feat_mat[a, 49] += 1
            elif all_atoms[b] == 'F':
                if dis_mat[a][b] < 5:
                    Feat_mat[a, 50] += 1
                else:
                    Feat_mat[a, 51] += 1
            elif all_atoms[b] == 'Br':
                if dis_mat[a][b] < 5:
                    Feat_mat[a, 52] += 1
                else:
                    Feat_mat[a, 53] += 1
            elif all_atoms[b] == 'S':
                if dis_mat[a][b] < 5:
                    Feat_mat[a, 54] += 1
                else:
                    Feat_mat[a, 55] += 1
            elif all_atoms[b] == 'Si':
                if dis_mat[a][b] < 5:
                    Feat_mat[a, 56] += 1
                else:
                    Feat_mat[a, 57] += 1
            elif all_atoms[b] == 'I':
                if dis_mat[a][b] < 5:
                    Feat_mat[a, 58] += 1
                else:
                    Feat_mat[a, 59] += 1
            else:
                if dis_mat[a][b] < 5:
                    Feat_mat[a, 60] += 1
                else:
                    Feat_mat[a, 61] += 1
    return Feat_mat

class TestbedDataset(InMemoryDataset):
    def __init__(self, root='/temp', dataset='_drug1',
                 xd=None, y=None, drug_info=None, distance=None, feat=None):
        super(TestbedDataset, self).__init__(root)
        #         self.dataset=dataset

        # 保存处理好的数据文件，文件存储在processed_path属性方法返回的文件路径
        # processed_paths属性方法在基类中定义，对self.processed_dir文件与
        # processed_file_names属性方法的返回的每一个文件名做一个拼接，然后返回
        self.distance = distance
        self.feat = feat
        self.dataset = dataset
        self.drug_info = drug_info
        print(self.processed_paths[0])
        if os.path.isfile(self.processed_paths[0]):
            print('Pre-processed data found: {}, loading ...'.format(self.processed_paths[0]))
            self.data, self.slices = torch.load(self.processed_paths[0])
        else:
            print('Pre-processed data {} not found, doing pre-processing...'.format(self.processed_paths[0]))
            self.process(xd, y)
            self.data, self.slices = torch.load(self.processed_paths[0])

    @property
    # 处理后的文件保存路径
    def processed_dir(self):
        return osp.join(self.root, 'processed')

    @property
    def raw_dir(self):
        return osp.join(self.root, 'raw')

    @property
    def raw_file_names(self):
        #         pass
        return ['drug_interaction_sample.csv']

    # raw_file_names 这个函数给出多张graph所存的路径，假设 graph a ,graph b，这里return就是两幅图对应的文件名

    def download(self):
        pass
        # 下载数据集，本地有就Pass

    @property
    def processed_file_names(self):
        return [self.dataset + '.pt']

    def process(self, xd, y):
        assert (len(xd) == len(y)), "The three lists must be the same length!"
        data_list = []
        data_len = len(xd)
        print('number of data', data_len)
        for j in tqdm(range(data_len)):
            # print('Converting SMILES to graph: {}/{}'.format(i+1, data_len))
            drug = xd[j]
            labels = float(y[j])
            # convert SMILES to molecular representation using rdkit

            edge_index = self.drug_info[drug][self.distance]
            features = self.drug_info[drug][self.feat]
            entity1_index = self.drug_info[drug]['index']
            # print("entity1_index",features,edge_index)
            # make the graph ready for PyTorch Geometrics GCN algorithms:

            GCNData = DATA.Data(x=torch.Tensor(features), edge_index=torch.LongTensor(edge_index),
                                y=torch.LongTensor([labels]), drug=torch.LongTensor([entity1_index]))

            data_list.append(GCNData)

        print('Graph construction done. Saving to file.')
        data, slices = self.collate(data_list)
        # save preprocessed data:
        torch.save((data, slices), self.processed_paths[0])

    def _process(self):
        if not os.path.exists(self.processed_dir):
            os.makedirs(self.processed_dir)

def load_data(ratio):
    # 根据路径读入相应的数据和smiles串
    print("create_G")
    G = nx.Graph()
    drug_info3 = read_data(drugs)
    positive = []
    with open(data_path, "r") as file:
        for line in file.readlines():
            # 如果两个药物都有smiles,则加入训练数据
            if line.strip().split("\t")[0] in drugs and line.strip().split("\t")[1] in drugs:
                positive.append([line.strip().split("\t")[0], line.strip().split("\t")[1]])
                G.add_edge(
                    line.strip().split("\t")[0], line.strip().split("\t")[1])
    print(nx.info(G))
    num_connections_to_remove = int(0.1 * len(positive))
    indices_to_remove = np.random.choice(len(positive), num_connections_to_remove, replace=False)
    for idx in indices_to_remove:
        node1, node2 = positive[idx]
        G.remove_edge(node1, node2)
    positive = [positive[idx] for idx in range(len(positive)) if idx not in indices_to_remove]

    negative_all = list(nx.non_edges(G))  # 构建负样本
    np.random.shuffle(negative_all)  # 随机打乱
    positive = np.array(positive)

    negative = np.asarray(negative_all[:len(positive)])  # 构建1：1正负样本

    print("positve examples: %d, negative examples: %d." % (len(positive), len(negative)))

    val_ratio = 0.1
    test_ratio = 0.1

    val_size = int(val_ratio * len(positive))  # 验证比例
    test_size = int(test_ratio * len(positive))  # 测试比例

    positive = np.concatenate([positive, np.ones(positive.shape[0], dtype=np.int64).reshape(positive.shape[0], 1)],
                              axis=1)
    # print(positive[:10])
    negative = np.concatenate([negative, np.zeros(negative.shape[0], dtype=np.int64).reshape(negative.shape[0], 1)],
                              axis=1)
    np.random.shuffle(positive)
    np.random.shuffle(negative)

    train_data3 = np.vstack((positive[: -(val_size + test_size)], negative[: -(val_size + test_size)]))
    np.random.shuffle(train_data3)
    val_data3 = np.vstack(
        (positive[-(val_size + test_size): -test_size], negative[-(val_size + test_size): -test_size]))
    np.random.shuffle(val_data3)
    test_data3 = np.vstack((positive[-test_size:], negative[-test_size:]))
    np.random.shuffle(test_data3)

    return train_data3, val_data3, test_data3, drug_info3

# datafile = "Biosnap_"
# root_path = './Dataset/data10'
# datafile = "AdverseDDI_"
# # 训练数据
# train_data, val_data, test_data, drug_info = load_data(ratio=0)
# train_0_2_0 = TestbedDataset(root=root_path, dataset=datafile + 'train1_0_2', xd=train_data[:, 0],
#                              y=train_data[:, 2], drug_info=drug_info, distance='adjacent1', feat='features1')
# train_0_2_1 = TestbedDataset(root=root_path, dataset=datafile + 'train2_0_2', xd=train_data[:, 1],
#                              y=train_data[:, 2], drug_info=drug_info, distance='adjacent1', feat='features1')
#
# train_2_4_0 = TestbedDataset(root=root_path, dataset=datafile + 'train1_2_4', xd=train_data[:, 0],
#                              y=train_data[:, 2], drug_info=drug_info, distance='adjacent2', feat='features2')
# train_2_4_1 = TestbedDataset(root=root_path, dataset=datafile + 'train2_2_4', xd=train_data[:, 1],
#                              y=train_data[:, 2], drug_info=drug_info, distance='adjacent2', feat='features2')
#
# train_4_6_0 = TestbedDataset(root=root_path, dataset=datafile + 'train1_4_6', xd=train_data[:, 0],
#                              y=train_data[:, 2], drug_info=drug_info, distance='adjacent3', feat='features3')
# train_4_6_1 = TestbedDataset(root=root_path, dataset=datafile + 'train2_4_6', xd=train_data[:, 1],
#                              y=train_data[:, 2], drug_info=drug_info, distance='adjacent3', feat='features3')
#
# train_6_8_0 = TestbedDataset(root=root_path, dataset=datafile + 'train1_6_8', xd=train_data[:, 0],
#                              y=train_data[:, 2], drug_info=drug_info, distance='adjacent4', feat='features4')
# train_6_8_1 = TestbedDataset(root=root_path, dataset=datafile + 'train2_6_8', xd=train_data[:, 1],
#                              y=train_data[:, 2], drug_info=drug_info, distance='adjacent4', feat='features4')
#
# train_10_0 = TestbedDataset(root=root_path, dataset=datafile + 'train1_10', xd=train_data[:, 0],
#                             y=train_data[:, 2], drug_info=drug_info, distance='adjacent5', feat='features5')
# train_10_1 = TestbedDataset(root=root_path, dataset=datafile + 'train2_10', xd=train_data[:, 1],
#                             y=train_data[:, 2], drug_info=drug_info, distance='adjacent5', feat='features5')
#
# # 验证数据
# valid_0_2_0 = TestbedDataset(root=root_path, dataset=datafile + 'valid1_0_2', xd=val_data[:, 0],
#                              y=val_data[:, 2], drug_info=drug_info, distance='adjacent1', feat='features1')
# valid_0_2_1 = TestbedDataset(root=root_path, dataset=datafile + 'valid2_0_2', xd=val_data[:, 1],
#                              y=val_data[:, 2], drug_info=drug_info, distance='adjacent1', feat='features1')
#
# valid_2_4_0 = TestbedDataset(root=root_path, dataset=datafile + 'valid1_2_4', xd=val_data[:, 0],
#                              y=val_data[:, 2], drug_info=drug_info, distance='adjacent2', feat='features2')
# valid_2_4_1 = TestbedDataset(root=root_path, dataset=datafile + 'valid2_2_4', xd=val_data[:, 1],
#                              y=val_data[:, 2], drug_info=drug_info, distance='adjacent2', feat='features2')
#
# valid_4_6_0 = TestbedDataset(root=root_path, dataset=datafile + 'valid1_4_6', xd=val_data[:, 0],
#                              y=val_data[:, 2], drug_info=drug_info, distance='adjacent3', feat='features3')
# valid_4_6_1 = TestbedDataset(root=root_path, dataset=datafile + 'valid2_4_6', xd=val_data[:, 1],
#                              y=val_data[:, 2], drug_info=drug_info, distance='adjacent3', feat='features3')
#
# valid_6_8_0 = TestbedDataset(root=root_path, dataset=datafile + 'valid1_6_8', xd=val_data[:, 0],
#                              y=val_data[:, 2], drug_info=drug_info, distance='adjacent4', feat='features4')
# valid_6_8_1 = TestbedDataset(root=root_path, dataset=datafile + 'valid2_6_8', xd=val_data[:, 1],
#                              y=val_data[:, 2], drug_info=drug_info, distance='adjacent4', feat='features4')
#
# valid_10_0 = TestbedDataset(root=root_path, dataset=datafile + 'valid1_10', xd=val_data[:, 0],
#                             y=val_data[:, 2], drug_info=drug_info, distance='adjacent5', feat='features5')
# valid_10_1 = TestbedDataset(root=root_path, dataset=datafile + 'valid2_10', xd=val_data[:, 1],
#                             y=val_data[:, 2], drug_info=drug_info, distance='adjacent5', feat='features5')
#
# # 测试数据
# test_0_2_0 = TestbedDataset(root=root_path, dataset=datafile + 'test1_0_2', xd=test_data[:, 0],
#                             y=test_data[:, 2], drug_info=drug_info, distance='adjacent1', feat='features1')
# test_0_2_1 = TestbedDataset(root=root_path, dataset=datafile + 'test2_0_2', xd=test_data[:, 1],
#                             y=test_data[:, 2], drug_info=drug_info, distance='adjacent1', feat='features1')
#
# test_2_4_0 = TestbedDataset(root=root_path, dataset=datafile + 'test1_2_4', xd=test_data[:, 0],
#                             y=test_data[:, 2], drug_info=drug_info, distance='adjacent2', feat='features2')
# test_2_4_1 = TestbedDataset(root=root_path, dataset=datafile + 'test2_2_4', xd=test_data[:, 1],
#                             y=test_data[:, 2], drug_info=drug_info, distance='adjacent2', feat='features2')
#
# test_4_6_0 = TestbedDataset(root=root_path, dataset=datafile + 'test1_4_6', xd=test_data[:, 0],
#                             y=test_data[:, 2], drug_info=drug_info, distance='adjacent3', feat='features3')
# test_4_6_1 = TestbedDataset(root=root_path, dataset=datafile + 'test2_4_6', xd=test_data[:, 1],
#                             y=test_data[:, 2], drug_info=drug_info, distance='adjacent3', feat='features3')
#
# test_6_8_0 = TestbedDataset(root=root_path, dataset=datafile + 'test1_6_8', xd=test_data[:, 0],
#                             y=test_data[:, 2], drug_info=drug_info, distance='adjacent4', feat='features4')
# test_6_8_1 = TestbedDataset(root=root_path, dataset=datafile + 'test2_6_8', xd=test_data[:, 1],
#                             y=test_data[:, 2], drug_info=drug_info, distance='adjacent4', feat='features4')
#
# test_10_0 = TestbedDataset(root=root_path, dataset=datafile + 'test1_10', xd=test_data[:, 0],
#                            y=test_data[:, 2], drug_info=drug_info, distance='adjacent5', feat='features5')
# test_10_1 = TestbedDataset(root=root_path, dataset=datafile + 'test2_10', xd=test_data[:, 1],
#                            y=test_data[:, 2], drug_info=drug_info, distance='adjacent5', feat='features5')
